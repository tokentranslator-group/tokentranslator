{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/valdecar/Documents/projects/project/parser/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "folder = \"env\"\n",
    "sourcedir = currentdir.split(folder)[0]\n",
    "sys.path.insert(0, sourcedir)\n",
    "# from env.equation.equation import Equation\n",
    "print(sourcedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавление нового терма скобочного терма\n",
    "Индексация: `a[i,j,] = a[j,i,] `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы добавить новый скобочный терм в Equation нужно:</br>\n",
    "> 1) Добавить input pattern в data/terms/input/wolfram/patterns\n",
    "\n",
    "> 2) Добавить правила грамматики в data/grammars\n",
    "\n",
    "> 3) Добавить новые термы в tranlator/tree/nodes\n",
    "\n",
    "> 4) Добавить терм в списки переменных terms_vars, terms_br: args/args_main\n",
    "\n",
    "> 5) Добавить slambda pattern в data/terms/slambda/sympy/patterns/brackets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Добавление input pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого создается класс в data/terms/input/wolfram/patterns в методе `__call__` которого должен возвращаться re pattern:<br>\n",
    "```\n",
    "\n",
    "    def __init__(self, net):\n",
    "        self.net = net\n",
    "        self.id = 'idx'\n",
    "        self.init_pattern()\n",
    "\n",
    "    def init_pattern(self):\n",
    "        \n",
    "        # find 1 or 1,1, or 11, 123, 1,:\n",
    "        self.idx = \"(?P<idx>((\\d)+|((\\d)+,)+))\"\n",
    "\n",
    "        # find a, aa, Aa:\n",
    "        self.obj = \"(?P<obj>\\w+)\"\n",
    "\n",
    "        # find a[1,2,3,]:\n",
    "        self.main = r\"%s\\[\" % (self.obj) \n",
    "        \n",
    "        self.gen = lambda: self.main\n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        return(self.gen())\n",
    "```\n",
    "\n",
    "После создания patterna необходимо добавить его в три списка файла `data/terms/input/wolfram/lex_net_wolfram.py`: \n",
    "> terms_gens - для tokenizera:<br>\n",
    ">>        terms_gens = [Base, ArgInt, ArgFloat, ArgDelay, ArgTime,\n",
    "                      Var, VarBdp, Coeffs, Bdp, Diff, Pow, Func,\n",
    "                      FreeVar, Time, DiffTimeVar, Dot, Idx]\n",
    "\n",
    "\n",
    "> patterns_order - для приоритета терма с другими   \n",
    ">>        patterns_order = ['diff',\n",
    "                          'bdp',\n",
    "                          'dot',\n",
    "                          'func',\n",
    "                          'idx',\n",
    "                          'diff_time',\n",
    "                          'var',\n",
    "                          'free_var',\n",
    "                          'time',\n",
    "                          'coeffs',\n",
    "                          'pow',\n",
    "                          'float']\n",
    "\n",
    "> map_ptg - отображения lex терма в терм грамматики\n",
    ">>         map_ptg = dict([('diff', 'a'),\n",
    "                        ('bdp', 'a'),\n",
    "                        ('diff_time', 'a'),\n",
    "                        ('var', 'a'),\n",
    "                        ('free_var', 'a'),\n",
    "                        ('time', 'a'),\n",
    "                        ('coeffs', 'a'),\n",
    "                        ('pow', 'w'),\n",
    "                        ('func', 'f'),\n",
    "                        ('float', 'a'),\n",
    "                        ('dot', 'a'),\n",
    "                         ('idx', 'i')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Добавить правила грамматики "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого создаются правила для скобок a[,] -> i,] в  data/grammars/gm_pow_f_args.py, согласованные с значением map_ptg['idx'] добавленным на предыдущем шаге:\n",
    "\n",
    "                 ('T', ('T', 'M', 'I')), ('T', ('I')),\n",
    "                 ('I', ('LI', 'E', 'RI')),\n",
    "                 ('V', ('LI', 'AI', 'RI')),\n",
    "                 ('AI', ('E', 'D', 'AI')), ('AI', ('E', 'D')),\n",
    "                 ('LI', ('i')), ('RI', (']'))\n",
    "                 ('D', ',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Добавить новые термы в tranlator/tree/nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо для корректного преобразования дерева разбора в дерево операций.\n",
    "В `self.brs` класса NodeR нужно добавить новые скобочные термы грамматики:\n",
    ">            `self.brs= ['(', ')', 'w', 'f', 'i', ']']`\n",
    "\n",
    "После этого уже можно построить дерево операций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from lex:\n",
      "[['i', 'a', ',', 'a', ',', ']'], ['='], ['i', 'a', ',', 'a', ',', ']']]\n",
      "\n",
      "tree:\n",
      "=\n",
      "child 0: br\n",
      "   child 0: i\n",
      "   child 1: args\n",
      "      child 0: a\n",
      "      child 1: a\n",
      "   child 2: ]\n",
      "child 1: br\n",
      "   child 0: i\n",
      "   child 1: args\n",
      "      child 0: a\n",
      "      child 1: a\n",
      "   child 2: ]\n"
     ]
    }
   ],
   "source": [
    "from env.equation.equation import Equation\n",
    "eq = Equation(\"a[i,j,] = a[j,i,]\")\n",
    "eq.parser.parse()\n",
    "\n",
    "print(\"from lex:\")\n",
    "print(eq.parser.eq)\n",
    "\n",
    "print(\"\\ntree:\")\n",
    "print(eq.eq_tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Добавить терм в списки переменных terms_vars, terms_br: args/args_main:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот шаг необходим для интерпретирования левой скобки (`a[`) как переменной со значением `a`\n",
    "Нужно добавтить в два списка:\n",
    ">               terms_vars = ['free_var', 'var', 'func', 'coeffs', 'idx']\n",
    "              terms_br = ['func', 'idx']\n",
    "  \n",
    "Теперь можно производить подстановки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "a = sympy.Matrix([[0, 1], [1, 0]])\n",
    "\n",
    "eq.args_editor.get_vars()\n",
    "eq.args_editor.subs(a=a, i=0, j=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Добавить slambda pattern в data/terms/slambda/sympy/patterns/brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно создать replacer для sympy семантики. Для этого создается класс Idx c `self.id` для поиска в списке термов:\n",
    "> self.id = 'l:i|r:]'\n",
    "\n",
    "Это означает, что левый скобочный терм i, правый ].\n",
    "\n",
    "Основная часть класса заключается в строчках\n",
    ">         self.func_name = left_node.args['variable']['value']\n",
    "        return(lambda *A, func=self.func_name: func.__getitem__(A))\n",
    "\n",
    "Это означает, что терм использует его значение для применения стандартного метода `__getitem__`. При этом количество индексов является произвольным (`*A`).\n",
    "Использование значения по умолчанию (`func=self.func_name`) необходимо для исключения переполнения одного значения для всех `idx` термов (т.к. в настоящей реализации один объект класса Idx используется для генерации значения всех `idx` термов в уравнении)<br><br>\n",
    "\n",
    "Теперь терм `a[i,j,]` имеет lambda представление т.е. его можно вызывать: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for matrix:\n",
      "Matrix([[0, 1], [1, 0]])\n",
      "\n",
      "\n",
      "a[i,j,]=a[j,i,]\n",
      "\n",
      "lambdify:\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eq.slambda.sympy.lambdify_sem()\n",
    "out = eq.slambda.sympy.lambdify()\n",
    "\n",
    "print(\"for matrix:\")\n",
    "print(a)\n",
    "print(\"\\n\")\n",
    "print(eq.sent)\n",
    "\n",
    "print(\"\\nlambdify:\")\n",
    "print(out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
