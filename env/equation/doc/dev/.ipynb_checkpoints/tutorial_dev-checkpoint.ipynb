{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/valdecar/Documents/projects/project/parser/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "folder = \"env\"\n",
    "sourcedir = currentdir.split(folder)[0]\n",
    "sys.path.insert(0, sourcedir)\n",
    "# from env.equation.equation import Equation\n",
    "print(sourcedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from env.equation.equation import Equation\n",
    "from translator.tokenizer.tokenizer_main import LexNetTokenizer\n",
    "from env.equation.data.terms.input.wolfram.lex_net_wolfram import LexNetW\n",
    "\n",
    "from translator.tree.maps import map_tree, map_tree_postproc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для преобразования термов wolfram в cpp можно было использовать обычный лексический анализ с помощью re: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', '*', '(DXM2 * (source[delay][idx + 1 * Block0StrideX * Block0CELLSIZE + 0] - 2.0 * source[delay][idx + 0 * Block0StrideX * Block0CELLSIZE + 0] + source[delay][idx-1 * Block0StrideX * Block0CELLSIZE + 0]))', 'params[2]', 'source[delay][idx + 0]']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eq = Equation(\"U-c*D[U,{x,2}]\")\n",
    "\n",
    "tokenizer = LexNetTokenizer(LexNetW())\n",
    "\n",
    "# make tokenization:\n",
    "lexem = tokenizer.lex(eq.sent)\n",
    "\n",
    "# convert lexem for cpp replacer:\n",
    "# for replacer One need nodes object\n",
    "# instead of Word. So need a tree.\n",
    "# parser.parse() create tree but\n",
    "# use it like list\n",
    "eq.parser.parse()\n",
    "lexem = eq.eq_tree\n",
    "\n",
    "eq.replacer.cpp.editor.set_default()\n",
    "\n",
    "# replace:\n",
    "# just use nodes in tree like in list\n",
    "cpp_map = [map_tree(term, eq.replacer.cpp.gen)\n",
    "           for term in lexem]\n",
    "out = [map_tree_postproc(term, eq.replacer.cpp.gen)\n",
    "       for term in cpp_map]\n",
    "\n",
    "print([o.output.cpp.out for o in out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, некоторые термы не потдаются лексическому разбору, например скобочные (функции, pow). Так, в следующем примере неопределенность к какому терму принадлежит скобка \"(\" перед U. Поэтому возникает необходимость использовать синтаксический анализ (восходящий разбор с использованием алгоритма Кока — Янгера — Касами https://en.wikipedia.org/wiki/CYK_algorithm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source[delay][idx + 0]=pow(source[delay][idx + 1]+(source[delay][idx + 0]+source[delay][idx + 1]),3)\n"
     ]
    }
   ],
   "source": [
    "eq_pow = Equation(\"U'=(V(t-3.1)+(U+V))^3\")\n",
    "eq_pow.parser.parse()\n",
    "eq_pow.replacer.cpp.editor.set_default()\n",
    "eq_pow.replacer.cpp.map_cpp()\n",
    "eq_pow.replacer.cpp.show_cpp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
